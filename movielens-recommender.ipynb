{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-26T05:09:06.690929Z",
     "iopub.status.busy": "2025-12-26T05:09:06.690552Z",
     "iopub.status.idle": "2025-12-26T05:09:06.696236Z",
     "shell.execute_reply": "2025-12-26T05:09:06.695325Z",
     "shell.execute_reply.started": "2025-12-26T05:09:06.690880Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first table is user ratings. The columns are user_id, item_id, rating, and timestamp. <br>\n",
    "Ratings range from 1-5, and the timestamp is probably in that 'seconds since the epoch' format. <br>\n",
    "Timestamp could be interesting if we're looking at how a users preferences are trending. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T05:09:06.700459Z",
     "iopub.status.busy": "2025-12-26T05:09:06.700126Z",
     "iopub.status.idle": "2025-12-26T05:09:06.774750Z",
     "shell.execute_reply": "2025-12-26T05:09:06.773829Z",
     "shell.execute_reply.started": "2025-12-26T05:09:06.700427Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>880</td>\n",
       "      <td>476</td>\n",
       "      <td>3</td>\n",
       "      <td>880175444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>716</td>\n",
       "      <td>204</td>\n",
       "      <td>5</td>\n",
       "      <td>879795543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>276</td>\n",
       "      <td>1090</td>\n",
       "      <td>1</td>\n",
       "      <td>874795795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>13</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "      <td>882399156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>12</td>\n",
       "      <td>203</td>\n",
       "      <td>3</td>\n",
       "      <td>879959583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  item_id  rating  timestamp\n",
       "0          196      242       3  881250949\n",
       "1          186      302       3  891717742\n",
       "2           22      377       1  878887116\n",
       "3          244       51       2  880606923\n",
       "4          166      346       1  886397596\n",
       "...        ...      ...     ...        ...\n",
       "99995      880      476       3  880175444\n",
       "99996      716      204       5  879795543\n",
       "99997      276     1090       1  874795795\n",
       "99998       13      225       2  882399156\n",
       "99999       12      203       3  879959583\n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ratings = pd.read_csv('/kaggle/input/movielens-100k-dataset/ml-100k/u.data', \n",
    "                           sep = '\\t', \n",
    "                           header=None,\n",
    "                           names = ['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "user_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is the movie table. The meat here is the one-hot-encoded genre tags and release dates. <br>\n",
    "We need a different encoding to handle some of the movie names, and need to specify the video release date type or else the csv parser will throw warnings. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T05:09:06.776306Z",
     "iopub.status.busy": "2025-12-26T05:09:06.776048Z",
     "iopub.status.idle": "2025-12-26T05:09:06.809508Z",
     "shell.execute_reply": "2025-12-26T05:09:06.808599Z",
     "shell.execute_reply.started": "2025-12-26T05:09:06.776286Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_name</th>\n",
       "      <th>release_date</th>\n",
       "      <th>video_release_date</th>\n",
       "      <th>imdb_link</th>\n",
       "      <th>unknown</th>\n",
       "      <th>action</th>\n",
       "      <th>adventure</th>\n",
       "      <th>animation</th>\n",
       "      <th>children</th>\n",
       "      <th>...</th>\n",
       "      <th>fantasy</th>\n",
       "      <th>film_noir</th>\n",
       "      <th>horror</th>\n",
       "      <th>musical</th>\n",
       "      <th>mystery</th>\n",
       "      <th>romance</th>\n",
       "      <th>sci_fi</th>\n",
       "      <th>thriller</th>\n",
       "      <th>war</th>\n",
       "      <th>western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>1678</td>\n",
       "      <td>Mat' i syn (1997)</td>\n",
       "      <td>06-Feb-1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Mat%27+i+syn+...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>1679</td>\n",
       "      <td>B. Monkey (1998)</td>\n",
       "      <td>06-Feb-1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?B%2E+Monkey+(...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>1680</td>\n",
       "      <td>Sliding Doors (1998)</td>\n",
       "      <td>01-Jan-1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/Title?Sliding+Doors+(1998)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>1681</td>\n",
       "      <td>You So Crazy (1994)</td>\n",
       "      <td>01-Jan-1994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?You%20So%20Cr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>1682</td>\n",
       "      <td>Scream of Stone (Schrei aus Stein) (1991)</td>\n",
       "      <td>08-Mar-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Schrei%20aus%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1682 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id                                  item_name release_date  \\\n",
       "0           1                           Toy Story (1995)  01-Jan-1995   \n",
       "1           2                           GoldenEye (1995)  01-Jan-1995   \n",
       "2           3                          Four Rooms (1995)  01-Jan-1995   \n",
       "3           4                          Get Shorty (1995)  01-Jan-1995   \n",
       "4           5                             Copycat (1995)  01-Jan-1995   \n",
       "...       ...                                        ...          ...   \n",
       "1677     1678                          Mat' i syn (1997)  06-Feb-1998   \n",
       "1678     1679                           B. Monkey (1998)  06-Feb-1998   \n",
       "1679     1680                       Sliding Doors (1998)  01-Jan-1998   \n",
       "1680     1681                        You So Crazy (1994)  01-Jan-1994   \n",
       "1681     1682  Scream of Stone (Schrei aus Stein) (1991)  08-Mar-1996   \n",
       "\n",
       "     video_release_date                                          imdb_link  \\\n",
       "0                   NaN  http://us.imdb.com/M/title-exact?Toy%20Story%2...   \n",
       "1                   NaN  http://us.imdb.com/M/title-exact?GoldenEye%20(...   \n",
       "2                   NaN  http://us.imdb.com/M/title-exact?Four%20Rooms%...   \n",
       "3                   NaN  http://us.imdb.com/M/title-exact?Get%20Shorty%...   \n",
       "4                   NaN  http://us.imdb.com/M/title-exact?Copycat%20(1995)   \n",
       "...                 ...                                                ...   \n",
       "1677                NaN  http://us.imdb.com/M/title-exact?Mat%27+i+syn+...   \n",
       "1678                NaN  http://us.imdb.com/M/title-exact?B%2E+Monkey+(...   \n",
       "1679                NaN      http://us.imdb.com/Title?Sliding+Doors+(1998)   \n",
       "1680                NaN  http://us.imdb.com/M/title-exact?You%20So%20Cr...   \n",
       "1681                NaN  http://us.imdb.com/M/title-exact?Schrei%20aus%...   \n",
       "\n",
       "      unknown  action  adventure  animation  children  ...  fantasy  \\\n",
       "0           0       0          0          1         1  ...        0   \n",
       "1           0       1          1          0         0  ...        0   \n",
       "2           0       0          0          0         0  ...        0   \n",
       "3           0       1          0          0         0  ...        0   \n",
       "4           0       0          0          0         0  ...        0   \n",
       "...       ...     ...        ...        ...       ...  ...      ...   \n",
       "1677        0       0          0          0         0  ...        0   \n",
       "1678        0       0          0          0         0  ...        0   \n",
       "1679        0       0          0          0         0  ...        0   \n",
       "1680        0       0          0          0         0  ...        0   \n",
       "1681        0       0          0          0         0  ...        0   \n",
       "\n",
       "      film_noir  horror  musical  mystery  romance  sci_fi  thriller  war  \\\n",
       "0             0       0        0        0        0       0         0    0   \n",
       "1             0       0        0        0        0       0         1    0   \n",
       "2             0       0        0        0        0       0         1    0   \n",
       "3             0       0        0        0        0       0         0    0   \n",
       "4             0       0        0        0        0       0         1    0   \n",
       "...         ...     ...      ...      ...      ...     ...       ...  ...   \n",
       "1677          0       0        0        0        0       0         0    0   \n",
       "1678          0       0        0        0        1       0         1    0   \n",
       "1679          0       0        0        0        1       0         0    0   \n",
       "1680          0       0        0        0        0       0         0    0   \n",
       "1681          0       0        0        0        0       0         0    0   \n",
       "\n",
       "      western  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "1677        0  \n",
       "1678        0  \n",
       "1679        0  \n",
       "1680        0  \n",
       "1681        0  \n",
       "\n",
       "[1682 rows x 24 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_metadata = pd.read_csv('/kaggle/input/movielens-100k-dataset/ml-100k/u.item',   \n",
    "                            sep='|',\n",
    "                            header=None,\n",
    "                            names = ['item_id', 'item_name', 'release_date', 'video_release_date',\n",
    "                                     'imdb_link','unknown', 'action', 'adventure', 'animation', 'children', \n",
    "                                     'comedy', 'crime', 'documentary', 'drama', 'fantasy', \n",
    "                                     'film_noir', 'horror', 'musical', 'mystery', 'romance', \n",
    "                                     'sci_fi', 'thriller', 'war', 'western'],\n",
    "                            dtype={'video_release_date':'str'},\n",
    "                            encoding='latin-1')\n",
    "movie_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User table. We have the occupation and the zip code here, which is pretty cool - this will allow us to find connections between class and location, and the types of movies people like. <br>\n",
    "Location data also gives us the opportunity to create cloropleth graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T05:09:06.810808Z",
     "iopub.status.busy": "2025-12-26T05:09:06.810471Z",
     "iopub.status.idle": "2025-12-26T05:09:06.826657Z",
     "shell.execute_reply": "2025-12-26T05:09:06.825747Z",
     "shell.execute_reply.started": "2025-12-26T05:09:06.810779Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>43537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>15213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>939</td>\n",
       "      <td>26</td>\n",
       "      <td>F</td>\n",
       "      <td>student</td>\n",
       "      <td>33319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>940</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>administrator</td>\n",
       "      <td>02215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>941</td>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>student</td>\n",
       "      <td>97229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>942</td>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>librarian</td>\n",
       "      <td>78209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>943</td>\n",
       "      <td>22</td>\n",
       "      <td>M</td>\n",
       "      <td>student</td>\n",
       "      <td>77841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  age gender     occupation zip code\n",
       "0          1   24      M     technician    85711\n",
       "1          2   53      F          other    94043\n",
       "2          3   23      M         writer    32067\n",
       "3          4   24      M     technician    43537\n",
       "4          5   33      F          other    15213\n",
       "..       ...  ...    ...            ...      ...\n",
       "938      939   26      F        student    33319\n",
       "939      940   32      M  administrator    02215\n",
       "940      941   20      M        student    97229\n",
       "941      942   48      F      librarian    78209\n",
       "942      943   22      M        student    77841\n",
       "\n",
       "[943 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_info = pd.read_csv('/kaggle/input/movielens-100k-dataset/ml-100k/u.user', \n",
    "                        sep='|',\n",
    "                        header=None,\n",
    "                        names = ['user_id', 'age', 'gender', 'occupation', 'zip code'])\n",
    "user_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T05:09:06.828561Z",
     "iopub.status.busy": "2025-12-26T05:09:06.828216Z",
     "iopub.status.idle": "2025-12-26T05:09:21.172938Z",
     "shell.execute_reply": "2025-12-26T05:09:21.171968Z",
     "shell.execute_reply.started": "2025-12-26T05:09:06.828533Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 80000\n",
      "Test samples: 19969\n",
      "\n",
      "SVD + XGBoost Performance:\n",
      "RMSE: 0.9775\n",
      "MAE: 0.7650\n",
      "\n",
      "Pure SVD Performance:\n",
      "RMSE: 1.2832\n",
      "MAE: 1.0269\n",
      "\n",
      "Improvement:\n",
      "RMSE reduction: 0.3057 (23.82%)\n",
      "MAE reduction: 0.2619 (25.50%)\n",
      "\n",
      "Top 10 most important features:\n",
      "            feature  importance\n",
      "150  svd_prediction    0.380465\n",
      "134  interaction_34    0.009098\n",
      "129  interaction_29    0.008898\n",
      "100   interaction_0    0.008751\n",
      "130  interaction_30    0.008719\n",
      "118  interaction_18    0.008718\n",
      "122  interaction_22    0.008544\n",
      "142  interaction_42    0.008500\n",
      "102   interaction_2    0.008420\n",
      "148  interaction_48    0.008363\n",
      "\n",
      "Sample predictions (first 5 test cases):\n",
      "User\tItem\tActual\tSVD\tXGB\tError(SVD)\tError(XGB)\n",
      "877\t381\t4\t3.73\t4.10\t0.27\t\t0.10\n",
      "815\t602\t3\t3.44\t3.07\t0.44\t\t0.07\n",
      "94\t431\t4\t3.52\t3.19\t0.48\t\t0.81\n",
      "416\t875\t2\t2.93\t2.29\t0.93\t\t0.29\n",
      "500\t182\t2\t4.23\t4.86\t2.23\t\t2.86\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Helper functions\n",
    "def extract_release_year(release_date_str):\n",
    "    \"\"\"Extract year from 'DD-Mon-YYYY' format, default to 1995 if missing\"\"\"\n",
    "    if pd.isna(release_date_str) or release_date_str == '':\n",
    "        return 1995\n",
    "    try:\n",
    "        date_obj = pd.to_datetime(release_date_str, format='%d-%b-%Y')\n",
    "        return date_obj.year\n",
    "    except:\n",
    "        return 1995\n",
    "\n",
    "def create_movie_features_lookup(movie_metadata):\n",
    "    \"\"\"Returns dict {item_id: np.array([19 genres + 1 normalized_year])}\"\"\"\n",
    "    # Extract and normalize release year\n",
    "    movie_metadata['release_year'] = movie_metadata['release_date'].apply(extract_release_year)\n",
    "    min_year = movie_metadata['release_year'].min()\n",
    "    max_year = movie_metadata['release_year'].max()\n",
    "    movie_metadata['year_normalized'] = (movie_metadata['release_year'] - min_year) / (max_year - min_year)\n",
    "\n",
    "    # Genre columns (19 one-hot encoded)\n",
    "    genre_cols = ['unknown', 'action', 'adventure', 'animation', 'children',\n",
    "                  'comedy', 'crime', 'documentary', 'drama', 'fantasy',\n",
    "                  'film_noir', 'horror', 'musical', 'mystery', 'romance',\n",
    "                  'sci_fi', 'thriller', 'war', 'western']\n",
    "\n",
    "    # Build dictionary\n",
    "    movie_dict = {}\n",
    "    for _, row in movie_metadata.iterrows():\n",
    "        item_id = row['item_id']\n",
    "        genre_features = row[genre_cols].values.astype(float)\n",
    "        year_feature = np.array([row['year_normalized']])\n",
    "        movie_dict[item_id] = np.concatenate([genre_features, year_feature])\n",
    "\n",
    "    return movie_dict\n",
    "\n",
    "def get_als_features(user_id, item_id, als_model, user_id_map, item_id_map):\n",
    "    \"\"\"Extract ALS latent factors as features\"\"\"\n",
    "    try:\n",
    "        # Map external IDs to internal indices\n",
    "        user_idx = user_id_map[user_id]\n",
    "        item_idx = item_id_map[item_id]\n",
    "\n",
    "        # Get user and item factors\n",
    "        user_factors = als_model.user_factors[user_idx]\n",
    "        item_factors = als_model.item_factors[item_idx]\n",
    "\n",
    "        # Predict rating via dot product\n",
    "        als_prediction = np.dot(user_factors, item_factors)\n",
    "\n",
    "        # Combine features\n",
    "        features = np.concatenate([\n",
    "            user_factors,\n",
    "            item_factors,\n",
    "            user_factors * item_factors,  # Element-wise interaction\n",
    "            [als_prediction]  # ALS prediction\n",
    "        ])\n",
    "        return features\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_enhanced_features(user_id, item_id, als_model, user_id_map, item_id_map, movie_features_dict):\n",
    "    \"\"\"Extract 171 features: 151 ALS + 19 genres + 1 year\"\"\"\n",
    "    # Get base ALS features (151 dims)\n",
    "    als_features = get_als_features(user_id, item_id, als_model, user_id_map, item_id_map)\n",
    "    if als_features is None:\n",
    "        return None\n",
    "\n",
    "    # Get movie metadata (20 dims)\n",
    "    movie_features = movie_features_dict.get(item_id, np.zeros(20))\n",
    "\n",
    "    # Concatenate\n",
    "    return np.concatenate([als_features, movie_features])\n",
    "\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    \"\"\"Calculate RMSE and MAE\"\"\"\n",
    "    y_pred_clipped = np.clip(y_pred, 1, 5)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred_clipped))\n",
    "    mae = mean_absolute_error(y_true, y_pred_clipped)\n",
    "    return {'Model': model_name, 'RMSE': rmse, 'MAE': mae}\n",
    "\n",
    "# 1. Load data into the pipeline\n",
    "\n",
    "# Load user ratings\n",
    "user_ratings = pd.read_csv('/kaggle/input/movielens-100k-dataset/ml-100k/u.data',\n",
    "                           sep='\\t',\n",
    "                           header=None,\n",
    "                           names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "\n",
    "# Load movie metadata\n",
    "movie_metadata = pd.read_csv('/kaggle/input/movielens-100k-dataset/ml-100k/u.item',\n",
    "                             sep='|', header=None,\n",
    "                             names=['item_id', 'item_name', 'release_date',\n",
    "                                    'video_release_date', 'imdb_link',\n",
    "                                    'unknown', 'action', 'adventure', 'animation', 'children',\n",
    "                                    'comedy', 'crime', 'documentary', 'drama', 'fantasy',\n",
    "                                    'film_noir', 'horror', 'musical', 'mystery', 'romance',\n",
    "                                    'sci_fi', 'thriller', 'war', 'western'],\n",
    "                             dtype={'video_release_date': 'str'},\n",
    "                             encoding='latin-1')\n",
    "\n",
    "df = user_ratings\n",
    "\n",
    "# 2. Split data into training and test sets in order to avoid data leakage\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Train ALS only on training data\n",
    "# Create ID mappings (external ID -> internal index)\n",
    "unique_users = sorted(train_df['user_id'].unique())\n",
    "unique_items = sorted(train_df['item_id'].unique())\n",
    "user_id_map = {uid: idx for idx, uid in enumerate(unique_users)}\n",
    "item_id_map = {iid: idx for idx, iid in enumerate(unique_items)}\n",
    "\n",
    "# Map training data to internal indices\n",
    "train_df['user_idx'] = train_df['user_id'].map(user_id_map)\n",
    "train_df['item_idx'] = train_df['item_id'].map(item_id_map)\n",
    "\n",
    "# Create sparse matrix (item x user format for implicit)\n",
    "# implicit expects confidence values, so we use ratings as-is\n",
    "user_item_matrix = csr_matrix(\n",
    "    (train_df['rating'].values, (train_df['item_idx'].values, train_df['user_idx'].values)),\n",
    "    shape=(len(unique_items), len(unique_users))\n",
    ")\n",
    "\n",
    "# Train ALS model\n",
    "als = AlternatingLeastSquares(factors=50, iterations=20, random_state=42)\n",
    "als.fit(user_item_matrix)\n",
    "\n",
    "print(f\"Trained ALS model with {len(unique_users)} users and {len(unique_items)} items\")\n",
    "\n",
    "# Calibrate ALS predictions to 1-5 scale using training data\n",
    "# Collect raw ALS predictions on training set\n",
    "train_als_raw_predictions = []\n",
    "train_actual_ratings = []\n",
    "\n",
    "for _, row in train_df.iterrows():\n",
    "    try:\n",
    "        user_idx = user_id_map[row['user_id']]\n",
    "        item_idx = item_id_map[row['item_id']]\n",
    "        raw_pred = np.dot(als.user_factors[user_idx], als.item_factors[item_idx])\n",
    "        train_als_raw_predictions.append(raw_pred)\n",
    "        train_actual_ratings.append(row['rating'])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "train_als_raw_predictions = np.array(train_als_raw_predictions)\n",
    "train_actual_ratings = np.array(train_actual_ratings)\n",
    "\n",
    "# Fit linear calibration: rating = a * raw_pred + b\n",
    "# Using least squares: minimize sum((a*x + b - y)^2)\n",
    "X_calib = np.column_stack([train_als_raw_predictions, np.ones(len(train_als_raw_predictions))])\n",
    "calib_params = np.linalg.lstsq(X_calib, train_actual_ratings, rcond=None)[0]\n",
    "als_scale, als_bias = calib_params\n",
    "\n",
    "print(f\"ALS calibration parameters: scale={als_scale:.4f}, bias={als_bias:.4f}\")\n",
    "\n",
    "# 4. Create movie features lookup\n",
    "movie_features_dict = create_movie_features_lookup(movie_metadata)\n",
    "print(f\"Created movie features for {len(movie_features_dict)} movies\")\n",
    "\n",
    "# 5. Create ALS-only features for training set (Model 2)\n",
    "X_train_als = []\n",
    "y_train_als = []\n",
    "\n",
    "for _, row in train_df.iterrows():\n",
    "    features = get_als_features(row['user_id'], row['item_id'], als, user_id_map, item_id_map)\n",
    "    if features is not None:\n",
    "        X_train_als.append(features)\n",
    "        y_train_als.append(row['rating'])\n",
    "\n",
    "X_train_als = np.array(X_train_als)\n",
    "y_train_als = np.array(y_train_als)\n",
    "\n",
    "# 6. Create ALS-only features for test set (Model 2) and track valid indices\n",
    "X_test_als = []\n",
    "y_test_als = []\n",
    "valid_test_indices = []  # Track which test_df rows have valid features\n",
    "\n",
    "for idx, row in test_df.iterrows():\n",
    "    features = get_als_features(row['user_id'], row['item_id'], als, user_id_map, item_id_map)\n",
    "    if features is not None:\n",
    "        X_test_als.append(features)\n",
    "        y_test_als.append(row['rating'])\n",
    "        valid_test_indices.append(idx)  # Store the original index\n",
    "\n",
    "X_test_als = np.array(X_test_als)\n",
    "y_test_als = np.array(y_test_als)\n",
    "\n",
    "print(f\"ALS-only features - Training samples: {len(X_train_als)}, Test samples: {len(X_test_als)}\")\n",
    "\n",
    "# 7. Create enhanced features for training set (Model 4)\n",
    "X_train_enhanced = []\n",
    "y_train_enhanced = []\n",
    "\n",
    "for _, row in train_df.iterrows():\n",
    "    features = get_enhanced_features(row['user_id'], row['item_id'], als, user_id_map, item_id_map, movie_features_dict)\n",
    "    if features is not None:\n",
    "        X_train_enhanced.append(features)\n",
    "        y_train_enhanced.append(row['rating'])\n",
    "\n",
    "X_train_enhanced = np.array(X_train_enhanced)\n",
    "y_train_enhanced = np.array(y_train_enhanced)\n",
    "\n",
    "# 8. Create enhanced features for test set (Model 4)\n",
    "X_test_enhanced = []\n",
    "y_test_enhanced = []\n",
    "\n",
    "for _, row in test_df.iterrows():\n",
    "    features = get_enhanced_features(row['user_id'], row['item_id'], als, user_id_map, item_id_map, movie_features_dict)\n",
    "    if features is not None:\n",
    "        X_test_enhanced.append(features)\n",
    "        y_test_enhanced.append(row['rating'])\n",
    "\n",
    "X_test_enhanced = np.array(X_test_enhanced)\n",
    "y_test_enhanced = np.array(y_test_enhanced)\n",
    "\n",
    "print(f\"Enhanced features - Training samples: {len(X_train_enhanced)}, Test samples: {len(X_test_enhanced)}\")\n",
    "\n",
    "# 9. Train XGBoost with ALS features (Model 2)\n",
    "xgb_als = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    objective='reg:squarederror'\n",
    ")\n",
    "xgb_als.fit(X_train_als, y_train_als)\n",
    "\n",
    "# 10. Train XGBoost with enhanced features (Model 4)\n",
    "xgb_enhanced = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    objective='reg:squarederror'\n",
    ")\n",
    "xgb_enhanced.fit(X_train_enhanced, y_train_enhanced)\n",
    "\n",
    "# 11. Evaluate all 4 models\n",
    "results = []\n",
    "\n",
    "# Model 1: Pure ALS - only predict for valid test indices (with calibration)\n",
    "y_pred_als = []\n",
    "for idx in valid_test_indices:\n",
    "    row = test_df.loc[idx]\n",
    "    try:\n",
    "        user_idx = user_id_map[row['user_id']]\n",
    "        item_idx = item_id_map[row['item_id']]\n",
    "        raw_prediction = np.dot(als.user_factors[user_idx], als.item_factors[item_idx])\n",
    "        # Apply calibration\n",
    "        calibrated_prediction = als_scale * raw_prediction + als_bias\n",
    "        y_pred_als.append(calibrated_prediction)\n",
    "    except:\n",
    "        # If user/item not in training set, use global mean (shouldn't happen for valid indices)\n",
    "        y_pred_als.append(train_df['rating'].mean())\n",
    "\n",
    "y_pred_als = np.array(y_pred_als)\n",
    "results.append(evaluate_model(y_test_als, y_pred_als, 'Model 1: Pure ALS'))\n",
    "\n",
    "# Model 2: XGBoost + ALS Features\n",
    "y_pred_xgb_als = xgb_als.predict(X_test_als)\n",
    "results.append(evaluate_model(y_test_als, y_pred_xgb_als, 'Model 2: XGBoost + ALS Features'))\n",
    "\n",
    "# Model 3: Pure ALS (same as Model 1)\n",
    "results.append(evaluate_model(y_test_als, y_pred_als, 'Model 3: Pure ALS'))\n",
    "\n",
    "# Model 4: XGBoost + ALS + Metadata\n",
    "y_pred_xgb_enhanced = xgb_enhanced.predict(X_test_enhanced)\n",
    "results.append(evaluate_model(y_test_enhanced, y_pred_xgb_enhanced,\n",
    "                              'Model 4: XGBoost + ALS + Metadata'))\n",
    "\n",
    "# 12. Display comparison table\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Add improvement columns\n",
    "baseline_rmse = results_df.iloc[0]['RMSE']\n",
    "baseline_mae = results_df.iloc[0]['MAE']\n",
    "results_df['RMSE_Improvement'] = results_df['RMSE'].apply(\n",
    "    lambda x: f\"{((baseline_rmse - x) / baseline_rmse * 100):.2f}%\"\n",
    ")\n",
    "results_df['MAE_Improvement'] = results_df['MAE'].apply(\n",
    "    lambda x: f\"{((baseline_mae - x) / baseline_mae * 100):.2f}%\"\n",
    ")\n",
    "\n",
    "# Format numeric columns\n",
    "results_df['RMSE'] = results_df['RMSE'].apply(lambda x: f\"{x:.4f}\")\n",
    "results_df['MAE'] = results_df['MAE'].apply(lambda x: f\"{x:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*100)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"=\"*100)\n",
    "\n",
    "# 13. Feature importance for enhanced model (Model 4)\n",
    "feature_names_enhanced = (\n",
    "    [f'user_factor_{i}' for i in range(50)] +\n",
    "    [f'item_factor_{i}' for i in range(50)] +\n",
    "    [f'interaction_{i}' for i in range(50)] +\n",
    "    ['als_prediction'] +\n",
    "    ['unknown', 'action', 'adventure', 'animation', 'children',\n",
    "     'comedy', 'crime', 'documentary', 'drama', 'fantasy',\n",
    "     'film_noir', 'horror', 'musical', 'mystery', 'romance',\n",
    "     'sci_fi', 'thriller', 'war', 'western'] +\n",
    "    ['release_year_normalized']\n",
    ")\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names_enhanced,\n",
    "    'importance': xgb_enhanced.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 Features (Model 4 - Enhanced):\")\n",
    "print(importance_df.head(15))\n",
    "\n",
    "# Metadata features only\n",
    "metadata_cols = ['unknown', 'action', 'adventure', 'animation', 'children',\n",
    "                 'comedy', 'crime', 'documentary', 'drama', 'fantasy',\n",
    "                 'film_noir', 'horror', 'musical', 'mystery', 'romance',\n",
    "                 'sci_fi', 'thriller', 'war', 'western', 'release_year_normalized']\n",
    "metadata_importance = importance_df[importance_df['feature'].isin(metadata_cols)]\n",
    "\n",
    "print(\"\\nMetadata Feature Importance:\")\n",
    "print(metadata_importance.sort_values('importance', ascending=False))\n",
    "print(f\"\\nTotal metadata contribution: {metadata_importance['importance'].sum()*100:.2f}%\")\n",
    "\n",
    "# 14. Sample predictions comparison\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"SAMPLE PREDICTIONS (First 5 test cases)\")\n",
    "print(\"=\"*100)\n",
    "print(f\"{'User':<6} {'Item':<6} {'Actual':<7} {'Model1':<7} {'Model2':<7} {'Model3':<7} {'Model4':<7}\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "for i in range(min(5, len(y_test_als))):\n",
    "    idx = valid_test_indices[i]\n",
    "    user = test_df.loc[idx]['user_id']\n",
    "    item = test_df.loc[idx]['item_id']\n",
    "    actual = y_test_als[i]\n",
    "    pred1 = np.clip(y_pred_als[i], 1, 5)\n",
    "    pred2 = np.clip(y_pred_xgb_als[i], 1, 5)\n",
    "    pred3 = np.clip(y_pred_als[i], 1, 5)\n",
    "    pred4 = np.clip(y_pred_xgb_enhanced[i], 1, 5)\n",
    "\n",
    "    print(f\"{user:<6} {item:<6} {actual:<7} {pred1:<7.2f} {pred2:<7.2f} {pred3:<7.2f} {pred4:<7.2f}\")\n",
    "print(\"=\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 626,
     "sourceId": 1187,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31239,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
